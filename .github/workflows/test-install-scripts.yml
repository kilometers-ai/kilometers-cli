name: Test Install Scripts

on:
  push:
    paths:
      - 'install.sh'
      - 'scripts/install.sh'
      - 'scripts/install.ps1'
      - 'scripts/test/**'
      - '.github/workflows/test-install-scripts.yml'
  pull_request:
    paths:
      - 'install.sh'
      - 'scripts/install.sh'
      - 'scripts/install.ps1'
      - 'scripts/test/**'
      - '.github/workflows/test-install-scripts.yml'
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Test mode'
        required: false
        default: 'normal'
        type: choice
        options:
          - normal
          - timeout
          - rate_limit
          - server_error
          - malformed_json
          - corrupted_binary
          - missing_binary
      platform:
        description: 'Platform to test (empty for all)'
        required: false
        type: string

permissions:
  contents: read

# Cancel in-progress runs for the same PR/branch
concurrency:
  group: test-install-${{ github.ref }}
  cancel-in-progress: true

env:
  TEST_MODE: ${{ github.event.inputs.test_mode || 'normal' }}
  TEST_PLATFORM: ${{ github.event.inputs.platform || '' }}

jobs:
  test-install-scripts:
    name: Test Install Scripts
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        platform:
          - ubuntu-amd64
          - alpine
          - debian
          - fedora
        test_mode:
          - normal
          - timeout
          - rate_limit
          - server_error
        exclude:
          # Reduce matrix size for PR builds
          - platform: debian
            test_mode: timeout
          - platform: fedora
            test_mode: rate_limit
          # Skip certain combinations on push to main
          - platform: alpine
            test_mode: server_error

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Cache Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-install-test-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-install-test-

      - name: Create test binaries
        run: |
          cd scripts/test/data
          ./create-test-binaries.sh

      - name: Start Docker services
        run: |
          cd scripts/test
          TEST_MODE=${{ matrix.test_mode }} docker compose up -d mock-server

          # Wait for mock server to be ready
          for i in {1..30}; do
            if curl -s http://localhost:8080/repos/kilometers-ai/kilometers-cli/releases/latest >/dev/null; then
              echo "Mock server is ready"
              break
            fi
            echo "Waiting for mock server... ($i/30)"
            sleep 2
          done

      - name: Test install scripts on ${{ matrix.platform }}
        run: |
          cd scripts/test
          ./test-install-docker.sh \
            --platform ${{ matrix.platform }} \
            --mode ${{ matrix.test_mode }} \
            --verbose

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.platform }}-${{ matrix.test_mode }}
          path: scripts/test/results/
          retention-days: 7

      - name: Show test logs
        if: failure()
        run: |
          echo "=== Test Logs ==="
          cd scripts/test
          for log in results/*.log; do
            if [ -f "$log" ]; then
              echo ""
              echo "--- $(basename $log) ---"
              cat "$log"
            fi
          done

      - name: Stop Docker services
        if: always()
        run: |
          cd scripts/test
          docker compose down --volumes

  # Job to test PowerShell script on Windows (if available)
  test-windows-install:
    name: Test Windows Install Script
    runs-on: windows-latest
    if: github.event_name != 'pull_request' # Only run on push/manual

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create mock release data
        shell: pwsh
        run: |
          # Create a simple mock km.exe for testing
          $mockBinary = @"
          @echo off
          echo Kilometers CLI v2024.1.1 (test build)
          if "%1"=="--version" echo km v2024.1.1-test
          if "%1"=="--help" (
            echo Usage: km [COMMAND]
            echo Commands:
            echo   init        Initialize configuration
            echo   monitor     Monitor MCP requests
            echo   --version   Show version
            echo   --help      Show this help
          )
          "@

          $mockBinary | Out-File -FilePath "km.exe.bat" -Encoding ASCII

          # Create zip archive
          Compress-Archive -Path "km.exe.bat" -DestinationPath "km-test.zip"

      - name: Test PowerShell install script (dry run)
        shell: pwsh
        run: |
          # Test script syntax and basic validation
          $scriptPath = "scripts/install.ps1"

          # Parse the script to check for syntax errors
          $null = [System.Management.Automation.PSParser]::Tokenize((Get-Content $scriptPath -Raw), [ref]$null)

          Write-Host "✓ PowerShell install script syntax is valid"

          # Test platform detection logic
          $arch = if ([Environment]::Is64BitOperatingSystem) { "x86_64" } else { "i686" }
          $platform = "$arch-pc-windows-msvc"

          Write-Host "✓ Platform detection: $platform"

  # Aggregate results job
  test-results:
    name: Install Script Test Results
    runs-on: ubuntu-latest
    needs: [test-install-scripts]
    if: always()

    steps:
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: test-results/

      - name: Generate test summary
        run: |
          echo "# Install Script Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          total_tests=0
          passed_tests=0

          for result_dir in test-results/*/; do
            if [ -d "$result_dir" ]; then
              platform_mode=$(basename "$result_dir")
              echo "## $platform_mode" >> $GITHUB_STEP_SUMMARY

              for log in "$result_dir"/*.log; do
                if [ -f "$log" ]; then
                  ((total_tests++))

                  if grep -q "All tests passed" "$log"; then
                    echo "✅ $(basename "$log")" >> $GITHUB_STEP_SUMMARY
                    ((passed_tests++))
                  else
                    echo "❌ $(basename "$log")" >> $GITHUB_STEP_SUMMARY
                    # Show first few error lines
                    echo '```' >> $GITHUB_STEP_SUMMARY
                    grep -A5 -B2 "\[FAIL\]" "$log" | head -10 >> $GITHUB_STEP_SUMMARY
                    echo '```' >> $GITHUB_STEP_SUMMARY
                  fi
                fi
              done
            fi
          done

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Summary: $passed_tests/$total_tests tests passed**" >> $GITHUB_STEP_SUMMARY

          # Set job result
          if [ "$passed_tests" -ne "$total_tests" ]; then
            echo "Some tests failed"
            exit 1
          fi

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            let comment = '## Install Script Test Results\n\n';

            // Read test results
            const resultsDir = 'test-results';
            if (fs.existsSync(resultsDir)) {
              const results = fs.readdirSync(resultsDir);

              for (const result of results) {
                const resultPath = path.join(resultsDir, result);
                if (fs.statSync(resultPath).isDirectory()) {
                  comment += `### ${result}\n`;

                  const logs = fs.readdirSync(resultPath).filter(f => f.endsWith('.log'));
                  for (const log of logs) {
                    const logPath = path.join(resultPath, log);
                    const content = fs.readFileSync(logPath, 'utf8');

                    if (content.includes('All tests passed')) {
                      comment += `✅ ${log}\n`;
                    } else {
                      comment += `❌ ${log}\n`;
                    }
                  }
                  comment += '\n';
                }
              }
            }

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const existingComment = comments.find(c =>
              c.user.login === 'github-actions[bot]' &&
              c.body.includes('Install Script Test Results')
            );

            if (existingComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: comment
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }
